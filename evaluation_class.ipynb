{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import linalg as LA\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models import NeuralNet\n",
    "from loss import SmoothSailing, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(batch_size=32, test_batch_size=1000, epochs=10,\n",
    "                       lr=0.0001, momentum=0.5, seed=1, log_interval=100, noise_level=0, beta=0.01)\n",
    "torch.manual_seed(config.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "    batch_size=config.batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=config.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = NeuralNet(size=2048).to(device)\n",
    "m = torch.load('model.pt', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "acc = 0\n",
    "\n",
    "num_repeats = 100\n",
    "\n",
    "for i in range(num_repeats):\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # add noise\n",
    "            data += config.noise_level * torch.randn_like(data)\n",
    "            data = Variable(data.view(-1, 28*28))\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            accur = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        acc += accur/config.test_batch_size*100\n",
    "\n",
    "print(f\"Accuracy: {acc/num_repeats:.2f}%\")\n",
    "\n",
    "# save the results\n",
    "with open('cond_class.txt', 'w') as f:\n",
    "    f.write(f\"\\tAccuracy: {acc/num_repeats:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:50:49) [Clang 16.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc65afc70096efb496869c64bd017358404fbe61e744c54c4a45505688b36bf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
